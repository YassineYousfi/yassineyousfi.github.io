<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Yassine  Yousfi</title>
<meta name="description" content="My Research and Teaching Homepage. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/">

<!-- Open Graph -->


<link type="text/css" href="/assets/css/magnifier.css" rel="stylesheet">
<script type="text/javascript" src="/assets/js/magnifier.js"></script>
  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light bg-white navbar-expand-sm fixed-top">
    <div class="container">
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              About
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              Blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/research/">
                Research
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                Teaching
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Yassine</span>   Yousfi
    </h1>
  </header>

  <article>
    

    <div class="clearfix">
      <p>I am passionate about machine intelligence.</p>

<p>I work as a head of Machine Learning at comma.ai where my focus is learning driving agents from data and in an end-to-end fashion.</p>

<p>To do so, we‚Äôre training World Models for driving. These World Models can be seen as ‚Äúsimulators‚Äù generating realistic driving video given driving inputs (steering, gas, etc.). World Models are useful for many reasons:</p>
<ul>
  <li>They are trained with very little supervision (self-supervised training)</li>
  <li>They can be used to generate synthetic data for other models to learn on-policy</li>
  <li>They can be used as powerful feature extractors</li>
  <li>They can be used as policies</li>
</ul>

<p>I hold a PhD in Electrical and Computer Engineering from Binghamton University (SUNY) where I researched digital media security topics such as Steganography/Steganalysis or Watermarking Deep Learning.</p>

<p>The take-away from my PhD was that when carefully scaling Machine Learning architecture and data, digital media security tasks can be learned end-to-end, with little domain specific preprocessing or tricks.</p>

<p>I also hold a MSc in Computer Science/Machine Learning from √âcole Centrale de Lille (France).</p>

    </div>

    
      <div class="news">
  <h2>News</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Jun 25, 2023</th>
          <td>
            
              I‚Äôm giving a talk at <a href="https://commacon.splashthat.com/" target="_blank">comma_con</a> titled ‚ÄúLearning a Driving Simulator.‚Äù Blog post coming soon.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jun 1, 2023</th>
          <td>
            
              I‚Äôm serving as a Technical Program Chair for the <a href="https://www.ihmmsec.org/cms/home/index.html" target="_blank">11th ACM Workshop on Information Hiding and Multimedia Security (IH&amp;MMSec)</a>

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jun 28, 2022</th>
          <td>
            
              Our new paper ‚ÄúDetector-Informed Batch Steganography and Pooled Steganalysis‚Äù won the Best Student Paper Award at the ACM Workshop on Information Hiding and Multimedia Security (IH&amp;MMSEC)!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">May 10, 2022</th>
          <td>
            
              I successfully defended my Ph.D. <a href="/assets/pdf/yassine_PhD_dissertation.pdf" target="_blank">dissertation</a> üéâ

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">May 1, 2022</th>
          <td>
            
              Excited about our new paper on Batch Steganography and Pooled Steganalysis accepted at the ACM Workshop on Information Hiding and Multimedia Security (IH&amp;MMSEC).

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>Selected publications</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">thesis</abbr>
    
  
  </div>

  <div id="dissertation" class="col-sm-8">
    
      <div class="title">DEEP LEARNING FOR IMAGE STEGANOGRAPHY AND STEGANALYSIS. CHALLENGES, ADVANCES, AND OPPORTUNITIES</div>
      <div class="author">
        
          
            
              <em>Yousfi, Y.</em>
            
          
        
      </div>

      <div class="periodical">
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="/assets/pdf/yassine_PhD_dissertation.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Deep learning has proven incredibly successful in a plethora of fields. In computer vision, deep neural networks are now the state-of-the-art for a variety of tasks. At the first glance, steganography and steganalysis appear to be very much different tasks than classical computer vision tasks, yet deep learning, especially convolutional neural networks, popularized by the computer vision field, have outperformed all classical feature-based approaches for detecting steganography. 
Intuitively, steganographic embedding changes are weak, noise-like signals executed primarily in complex content, such as textures and edges. Since computer vision classifies and categorizes content, it is also suitable for detecting the presence of noise-like stego signals modulated by content.
In this dissertation, we focus on refactoring steganography detectors with more modern and general components, qualitatively understanding their strengths and failure cases, and using them algorithmically to improve steganography. First, we show that many custom ingredients long believed to be necessary for successfully training a deep neural network for steganography detection can be omitted in favor of more general-purpose convolutional architectures with very few domain-specific changes. Next, we focus on understanding what makes deep neural networks superior to their classical feature-based predecessors. Lastly, we use these powerful steganography detectors as a feedback loop in novel batch steganography algorithms, which allocate more payload in images where state-of-the-art detectors fail to detect steganography.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://www.ihmmsec.org/cms/front_content.php?idcat=69&lang=2" target="_blank">IH</a></abbr>
    
  
  </div>

  <div id="yassine22batch" class="col-sm-8">
    
      <div class="title">Detector-Informed Batch Steganography and Pooled Steganalysis</div>
      <div class="author">
        
          
            
              
                <em>Yousfi, Y.</em>,
              
            
          
        
          
            
              
                
                  Dworetzky, E.,
                
              
            
          
        
          
            
              
                
                  and Fridrich, J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In The 10th ACM Workshop on Information Hiding and Multimedia Security</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="http://www.ws.binghamton.edu/fridrich/Research/BS-revision-jf.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Abstract We study the problem of batch steganography when the senders use feedback from a steganography detector. This brings an additional level of complexity to the table due to the highly non-linear and non-Gaussian response of modern steganalysis detectors as well as the necessity to study the impact of the inevitable mismatch between senders‚Äô and Warden‚Äôs detectors. Two payload spreaders are considered based on the oracle generating possible cover images. Three different pooling strategies are devised and studied for a more comprehensive assessment of security. Substantial security gains are observed with respect to previous art ‚Äì the detector-agnostic image-merging sender. Close attention is paid to the impact of the information available to the Warden on security.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://wifs2021.lirmm.fr/" target="_blank">WIFS21</a></abbr>
    
  
  </div>

  <div id="yousfi21ldeas" class="col-sm-8">
    
      <div class="title">CNN Steganalyzers Leverage Local Embedding Artifacts</div>
      <div class="author">
        
          
            
              
                <em>Yousfi, Y.</em>,
              
            
          
        
          
            
              
                
                  Butora, J.,
                
              
            
          
        
          
            
              
                
                  and Fridrich, J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In IEEE International Workshop on Information Forensics and Security</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="http://www.ws.binghamton.edu/fridrich/Research/lDEAs_v7.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
      
      <a href="/assets/pdf/LDEAs_slides_v3.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>While convolutional neural networks have firmly established themselves as the superior steganography detectors, little human-interpretable feedback to the steganographer as to how the network reaches its decision has so far been obtained from trained models. The folklore has it that, unlike rich models, which rely on global statistics, CNNs can leverage spatially localized signals. In this paper, we adapt existing attribution tools, such as Integrated Gradients and Last Activation Maps, to show that CNNs can indeed find overwhelming evidence for steganography from a few highly localized embedding artifacts. We look at the nature of these artifacts via case studies of both modern content-adaptive and older steganographic algorithms. The main culprit is linked to ‚Äúcontent creating changes‚Äù when the magnitude of a DCT coefficient is increased (Jsteg, ‚ÄìF5), which can be especially detectable for high frequency DCT modes that were originally zeros (J-MiPOD). In contrast, J-UNIWARD introduces the smallest number of locally detectable embedding artifacts among all tested algorithms.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://www.ihmmsec.org/cms/front_content.php?idcat=69&lang=2" target="_blank">IH</a></abbr>
    
  
  </div>

  <div id="surgeries21ih" class="col-sm-8">
    
      <div class="title">Improving EfficientNet for JPEG Steganalysis</div>
      <div class="author">
        
          
            
              
                <em>Yousfi, Y.</em>,
              
            
          
        
          
            
              
                
                  Butora, J.,
                
              
            
          
        
          
            
              
                
                  Fridrich, J.,
                
              
            
          
        
          
            
              
                
                  and Fuji-Tsang, C.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In The 9th ACM Workshop on Information Hiding and Multimedia Security</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="http://www.ws.binghamton.edu/fridrich/Research/11_SURGERIES_v8_preprint.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this paper, we study the EfficientNet family pre-trained on ImageNet when used for steganalysis using transfer learning. We show that certain ‚Äúsurgical modifications‚Äù aimed at maintaining the input resolution in EfficientNet architectures significantly boost their performance in JPEG steganalysis, establishing thus new benchmarks. The modified models are evaluated by their detection accuracy, the number of parameters, the memory consumption, and the total floating point operations (FLOPs) on the ALASKA II dataset. We also show that, surprisingly, EfficientNets in their ‚Äúvanilla form‚Äù do not perform as well as the SRNet in BOSSbase+BOWS2. This is because, unlike ALASKA II images, BOSSbase+BOWS2 contains aggressively subsampled images with more complex content. The surgical modifications in EfficientNet remedy this underperformance as well.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://www.wifs2020.nyu.edu/home" target="_blank">WIFS20</a></abbr>
    
  
  </div>

  <div id="yousfi20imagenet" class="col-sm-8">
    
      <div class="title">ImageNet Pre-trained CNNs for JPEG Steganalysis</div>
      <div class="author">
        
          
            
              
                <em>Yousfi, Y.</em>,
              
            
          
        
          
            
              
                
                  Butora, J.,
                
              
            
          
        
          
            
              
                
                  Khvedchenya, E.,
                
              
            
          
        
          
            
              
                
                  and Fridrich, J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In IEEE International Workshop on Information Forensics and Security</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="http://www.ws.binghamton.edu/fridrich/Research/Alaska-2-Revised.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/BloodAxe/Kaggle-2020-Alaska2" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
      <a href="https://drive.google.com/file/d/1CTfo0_12pCnrM-vaMUcn7ifUJOMZiqg5/view?usp=sharing" class="btn btn-sm z-depth-0" role="button" target="_blank">Video</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this paper, we investigate pre-trained computervision deep architectures, such as the EfficientNet, MixNet, and ResNet for steganalysis. These models pre-trained on ImageNet can be rather quickly refined for JPEG steganalysis while offering significantly better performance than CNNs designed purposely for steganalysis, such as the SRNet, trained from scratch. We show how different architectures compare on the ALASKA II dataset. We demonstrate that avoiding pooling/stride in the first layers enables better performance, as noticed by other top competitors, which aligns with the design choices of many CNNs designed for steganalysis. We also show how pre-trained computer-vision deep architectures perform on the ALASKA I dataset.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://signalprocessingsociety.org/publications-resources/ieee-signal-processing-letters" target="_blank">SPL</a></abbr>
    
  
  </div>

  <div id="yousfi20onehot" class="col-sm-8">
    
      <div class="title">An Intriguing Struggle of CNNs in JPEG Steganalysis and the OneHot Solution</div>
      <div class="author">
        
          
            
              
                <em>Yousfi, Y.</em>,
              
            
          
        
          
            
              
                
                  and Fridrich, J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Signal Processing Letters</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="http://www.ws.binghamton.edu/fridrich/Research/OneHot_Revised.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/YassineYousfi/OneHotConv" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Deep convolutional neural networks (CNNs) have become the tool of choice for steganalysis because they outperform older feature-based detectors by a large margin. However, recent work points at cases where feature-based detectors perform better than CNNs due to their failure to compute simple statistics of DCT coefficients. We introduce a shallow ‚ÄúOneHot‚Äù CNN, which encodes DCT coefficients using clipped one-hot encoding into a binary volumetric representation of the DCT plane fed to a convolutional block designed to learn relevant intra-block and inter-block relationships using vanilla and dilated convolutions. Methodology for plugging the ‚ÄúOneHot‚Äù network into conventional steganalysis CNNs is also introduced for an end-to-end learnable detector with improved performance</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://www.imaging.org/site/IST/IST/Conferences/EI/Symposium_Overview.aspx" target="_blank">EI</a></abbr>
    
  
  </div>

  <div id="yousfi20ei" class="col-sm-8">
    
      <div class="title">JPEG steganalysis detectors scalable with respect to compression quality</div>
      <div class="author">
        
          
            
              
                <em>Yousfi, Y.</em>,
              
            
          
        
          
            
              
                
                  and Fridrich, J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings IS&T, Electronic Imaging, Media Watermarking, Security, and Forensics</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="http://www.ws.binghamton.edu/fridrich/Research/scalable_jpeg_steganalysis.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Practical steganalysis inevitably involves the necessity to deal with a diverse cover source. In the JPEG domain, one key element of the diversification is the JPEG quality factor, or, more generally, the JPEG quantization table used for compression. This paper investigates experimentally the scalability of various steganalysis detectors w.r.t. JPEG quality. In particular, we report that CNN detectors as well as older feature-based detectors have the capacity to contain the complexity of multiple JPEG quality factors within a single model when the quality factors are properly grouped based on their quantization tables. Detectors trained on multiple JPEG qualities show no loss of detection accuracy when compared with dedicated detectors trained for a specific JPEG quality factor. We also demonstrate that CNNs (but not so much feature-based classifiers) trained on multiple qualities can generalize to unseen custom quantization tables compared to detectors trained for specific JPEG qualities. Their ability to generalize to very different quantization tables, however, remains a challenging task. A semi-metric comparing quantization tables is introduced and used to interpret our results.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge"><a href="https://www.ihmmsec.org/cms/front_content.php?idcat=69&lang=2" target="_blank">IH</a></abbr>
    
  
  </div>

  <div id="You19ih" class="col-sm-8">
    
      <div class="title">Breaking ALASKA: Color Separation for Steganalysis in JPEG Domain</div>
      <div class="author">
        
          
            
              
                <em>Yousfi, Y.</em>,
              
            
          
        
          
            
              
                
                  Butora, J.,
                
              
            
          
        
          
            
              
                
                  Giboulot, Q.,
                
              
            
          
        
          
            
              
                
                  and Fridrich, J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In The 7th ACM Workshop on Information Hiding and Multimedia Security</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="http://www.ws.binghamton.edu/fridrich/Research/ALASKA-preprint1.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper describes the architecture and training of detectors developed for the ALASKA steganalysis challenge. For each quality factor in the range 60‚Äì98, several multi-class tile detectors implemented as SRNets were trained on various combinations of three input channels: luminance and two chrominance channels. To accept images of arbitrary size, the detector for each quality factor was a multi-class multi-layered perceptron trained on features extracted by the tile detectors. For quality 99 and 100, a new ‚Äúreverse JPEG compatibility attack‚Äù was developed and also implemented using the SRNet via the tile detector. Throughout the paper, we explain various improvements we discovered during the course of the competition and discuss the challenges we encountered and trade offs that had to be adopted in order to build a detector capable of detecting steganographic content in a stego source of great diversity.</p>
    </div>
    
  </div>
</div>
</li></ol>
</div>

    

    
    <div class="social">
      <span class="contact-icon text-center">
  <a href="mailto:%79%79%6F%75%73%66%69%31@%62%69%6E%67%68%61%6D%74%6F%6E.%65%64%75"><i class="fas fa-envelope fa-xs"></i></a>
  
  <a href="https://scholar.google.com/citations?user=6M5diMgAAAAJ&hl" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar  fa-xs"></i></a>
  
  
  <a href="https://github.com/YassineYousfi" target="_blank" title="GitHub"><i class="fab fa-github  fa-xs"></i></a>
  <a href="https://www.linkedin.com/in/yassine-yousfi-" target="_blank" title="LinkedIn"><i class="fab fa-linkedin fa-xs"></i></a>
  <a href="https://twitter.com/yassineyousfi_" target="_blank" title="Twitter"><i class="fab fa-twitter fa-xs"></i></a>
  
  
  
  
</span>

      <div class="contact-note"></div>
    </div>
    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2024 Yassine  Yousfi.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
  </div>
</footer>



  </body>

  <!-- Load Core and Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha512-/DXTXr6nQodMUiq+IUJYCt2PPOUjrHJ9wFrqpJ3XkgPNOZVfMok7cRw6CSxyCQxXn6ozlESsSh1/sMCTF1rL/g==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js"  integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />


<!-- Load KaTeX -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
<script src="/assets/js/katex.js"></script>



<!-- Load Mansory & imagesLoaded -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="" crossorigin="anonymous"></script>
<script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>

<!-- Project Cards Layout -->
<script type="text/javascript">
  // Init Masonry
  var $grid = $('.grid').masonry({
    gutter: 10,
    horizontalOrder: true,
    itemSelector: '.grid-item',
  });
  // layout Masonry after each image loads
  $grid.imagesLoaded().progress( function() {
    $grid.masonry('layout');
  });
</script>





<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-156022446-1', 'auto');
ga('send', 'pageview');
</script>



</html>
