{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import Imputer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.loadtxt(\"X_train.csv\")\n",
    "y_train = np.loadtxt(\"y_train.csv\")\n",
    "X_test = np.loadtxt(\"X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_val_pimped(clf, X_train, y_train, n):\n",
    "    r = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        idx_train_1 = (np.where(y_train==1))[0]\n",
    "        idx_train_0 = (np.where(y_train==0))[0]\n",
    "        \n",
    "        idx_test_1 = np.random.choice(idx_train_1, size=278, replace=False)\n",
    "        idx_test_2 = np.random.choice(idx_train_0, size=1112, replace=False)\n",
    "        \n",
    "        idx_train_train_1 = np.setdiff1d(idx_train_1,idx_test_1)\n",
    "        idx_train_train_2 = np.random.choice(np.setdiff1d(idx_train_0,idx_test_2), size=27994, replace=False)\n",
    "        \n",
    "        idx_test = np.r_[idx_test_1, idx_test_2]\n",
    "        idx_train = np.r_[idx_train_train_1, idx_train_train_2]\n",
    "        \n",
    "        X_train_train = X_train[idx_train]\n",
    "        X_train_test = X_train[idx_test]\n",
    "        y_train_train = y_train[idx_train]\n",
    "        y_train_test = y_train[idx_test]\n",
    "        \n",
    "        clf.fit(X_train_train, y_train_train)\n",
    "        y_pred = clf.predict(X_train_test)\n",
    "        r[i] = (accuracy_score(y_pred, y_train_test))\n",
    "    print(r)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imputer = Imputer(strategy = 'median')\n",
    "X_train_i = imputer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_1 = X_train_i[:,21]*X_train_i[:,24] + X_train_i[:,26]\n",
    "feature_2 = X_train_i[:,46]/(X_train_i[:,26]+0.0001)\n",
    "feature_3 = X_train_i[:,17]-X_train_i[:,33]\n",
    "feature_4 = X_train_i[:,10]*X_train_i[:,43]\n",
    "feature_5 = X_train_i[:,12]-X_train_i[:,45]\n",
    "feature_6 = X_train_i[:,20]+X_train_i[:,61]\n",
    "feature_7 = X_train_i[:,1]-X_train_i[:,44]\n",
    "feature_8 = X_train_i[:,26]+X_train_i[:,31]/(X_train_i[:,14]+0.0001)\n",
    "feature_9 = X_train_i[:,23]/(X_train_i[:,26]+0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = np.c_[feature_1,\n",
    "                 feature_2,\n",
    "                 feature_3,\n",
    "                 feature_4,\n",
    "                 feature_5,\n",
    "                 feature_6,\n",
    "                 feature_7,\n",
    "                 feature_8,\n",
    "                 feature_9]\n",
    "feature_nan = np.sum(np.isnan(X_train),axis=1)\n",
    "X_train_plus = np.c_[X_train, np.isnan(X_train), features, feature_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imputer = Imputer(strategy = 'median')\n",
    "X_train_plus_i = imputer.fit_transform(X_train_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params1 = {'max_depth': 5, \n",
    "           'gamma': 0.5819,\n",
    "           'colsample_bytree': 0.8125,\n",
    "           'scale_pos_weight': 86, \n",
    "           'n_estimators': 240,\n",
    "           'learning_rate': 0.1027}\n",
    "\n",
    "model = XGBClassifier(nthread=4, **params1)\n",
    "model.fit(X_train_plus_i, y_train)\n",
    "\n",
    "thresholds = np.sort(model.feature_importances_)\n",
    "results = np.zeros((len(thresholds),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9294964   0.92086331  0.9294964   0.91870504  0.92086331  0.92302158\n",
      "  0.92014388  0.91510791]\n",
      "[ 0.91798561  0.90647482  0.91366906  0.92230216  0.91582734  0.92589928\n",
      "  0.93309353  0.93597122]\n",
      "[ 0.91510791  0.91366906  0.92374101  0.92517986  0.92086331  0.92302158\n",
      "  0.92589928  0.91151079]\n",
      "[ 0.91582734  0.9057554   0.91942446  0.93884892  0.92302158  0.92086331\n",
      "  0.92230216  0.92230216]\n",
      "[ 0.92517986  0.92086331  0.92877698  0.93309353  0.92589928  0.91798561\n",
      "  0.92230216  0.92086331]\n",
      "[ 0.91438849  0.92374101  0.93093525  0.92733813  0.91942446  0.93021583\n",
      "  0.92086331  0.93093525]\n",
      "[ 0.91798561  0.92014388  0.93165468  0.92374101  0.92374101  0.91798561\n",
      "  0.93021583  0.92446043]\n",
      "[ 0.91870504  0.92158273  0.92517986  0.93093525  0.91223022  0.92014388\n",
      "  0.91151079  0.92805755]\n",
      "[ 0.92661871  0.91294964  0.91654676  0.91223022  0.92446043  0.92517986\n",
      "  0.92374101  0.92661871]\n",
      "[ 0.93021583  0.90863309  0.92158273  0.92374101  0.91366906  0.92086331\n",
      "  0.9323741   0.92302158]\n",
      "Iteration 10 on 138\n",
      "[ 0.91582734  0.93309353  0.91654676  0.93165468  0.92302158  0.93165468\n",
      "  0.92086331  0.91870504]\n",
      "[ 0.91366906  0.92517986  0.92446043  0.91510791  0.93309353  0.92661871\n",
      "  0.92589928  0.92302158]\n",
      "[ 0.91079137  0.93597122  0.92661871  0.9352518   0.92158273  0.91366906\n",
      "  0.92158273  0.92589928]\n",
      "[ 0.91582734  0.91151079  0.91294964  0.92014388  0.94388489  0.92517986\n",
      "  0.91582734  0.92230216]\n",
      "[ 0.9294964   0.91582734  0.92877698  0.92014388  0.91726619  0.92302158\n",
      "  0.92302158  0.92374101]\n",
      "[ 0.91942446  0.90791367  0.93165468  0.91366906  0.91870504  0.92230216\n",
      "  0.92446043  0.93309353]\n",
      "[ 0.92517986  0.92446043  0.91870504  0.91798561  0.92446043  0.92661871\n",
      "  0.92230216  0.92086331]\n",
      "[ 0.91654676  0.93453237  0.92302158  0.92517986  0.91870504  0.93381295\n",
      "  0.92230216  0.91798561]\n",
      "[ 0.94100719  0.92014388  0.92446043  0.91870504  0.92374101  0.92374101\n",
      "  0.92158273  0.91798561]\n",
      "[ 0.90935252  0.91726619  0.9323741   0.93309353  0.92086331  0.92446043\n",
      "  0.9294964   0.91582734]\n",
      "Iteration 20 on 138\n",
      "[ 0.92230216  0.92517986  0.92589928  0.90935252  0.92158273  0.92230216\n",
      "  0.91870504  0.91223022]\n",
      "[ 0.93309353  0.92517986  0.92014388  0.92446043  0.91798561  0.91510791\n",
      "  0.92446043  0.91942446]\n",
      "[ 0.91942446  0.92589928  0.92589928  0.91798561  0.92230216  0.92230216\n",
      "  0.91582734  0.91294964]\n",
      "[ 0.91366906  0.92086331  0.91870504  0.91438849  0.91942446  0.93309353\n",
      "  0.90935252  0.92014388]\n",
      "[ 0.9294964   0.91726619  0.91294964  0.92733813  0.91582734  0.92877698\n",
      "  0.9323741   0.91366906]\n",
      "[ 0.91366906  0.90935252  0.92014388  0.91870504  0.93309353  0.92805755\n",
      "  0.91510791  0.93669065]\n",
      "[ 0.91798561  0.91007194  0.91726619  0.92517986  0.92661871  0.91726619\n",
      "  0.91654676  0.92661871]\n",
      "[ 0.91510791  0.93093525  0.92517986  0.91942446  0.90935252  0.92661871\n",
      "  0.92446043  0.92446043]\n",
      "[ 0.91510791  0.91798561  0.9294964   0.91294964  0.93165468  0.92805755\n",
      "  0.92517986  0.92589928]\n",
      "[ 0.92877698  0.91582734  0.92589928  0.91582734  0.92014388  0.92805755\n",
      "  0.92086331  0.92446043]\n",
      "Iteration 30 on 138\n",
      "[ 0.92877698  0.92517986  0.92589928  0.91294964  0.92086331  0.92014388\n",
      "  0.92446043  0.92877698]\n",
      "[ 0.91798561  0.92733813  0.92230216  0.92661871  0.92158273  0.93021583\n",
      "  0.92446043  0.92446043]\n",
      "[ 0.91438849  0.92733813  0.92158273  0.91798561  0.92230216  0.92302158\n",
      "  0.92230216  0.91438849]\n",
      "[ 0.91870504  0.91726619  0.91798561  0.93453237  0.91294964  0.91151079\n",
      "  0.92230216  0.92374101]\n",
      "[ 0.93165468  0.92805755  0.91582734  0.91582734  0.91870504  0.91582734\n",
      "  0.91942446  0.9294964 ]\n",
      "[ 0.91798561  0.91798561  0.93021583  0.91294964  0.92230216  0.91942446\n",
      "  0.92733813  0.93597122]\n",
      "[ 0.9294964   0.9323741   0.91942446  0.9323741   0.92589928  0.91582734\n",
      "  0.92302158  0.91510791]\n",
      "[ 0.91151079  0.92230216  0.92086331  0.92589928  0.91942446  0.92589928\n",
      "  0.91654676  0.92086331]\n",
      "[ 0.93165468  0.91366906  0.92086331  0.92877698  0.92446043  0.91942446\n",
      "  0.92517986  0.92446043]\n",
      "[ 0.92158273  0.91798561  0.92230216  0.91438849  0.93021583  0.91654676\n",
      "  0.91654676  0.9294964 ]\n",
      "Iteration 40 on 138\n",
      "[ 0.92302158  0.91079137  0.90791367  0.93165468  0.91942446  0.91942446\n",
      "  0.92589928  0.92086331]\n",
      "[ 0.92446043  0.93165468  0.91223022  0.92517986  0.91870504  0.91582734\n",
      "  0.9294964   0.92446043]\n",
      "[ 0.93309353  0.92446043  0.91007194  0.93597122  0.91582734  0.92014388\n",
      "  0.92517986  0.93597122]\n",
      "[ 0.92446043  0.92805755  0.92158273  0.91726619  0.92302158  0.91294964\n",
      "  0.91870504  0.91654676]\n",
      "[ 0.93165468  0.92589928  0.91726619  0.91798561  0.93165468  0.91223022\n",
      "  0.92733813  0.91654676]\n",
      "[ 0.92517986  0.92877698  0.92661871  0.92517986  0.92446043  0.92014388\n",
      "  0.92661871  0.92374101]\n",
      "[ 0.9352518   0.92086331  0.93165468  0.92877698  0.92374101  0.92158273\n",
      "  0.92517986  0.91654676]\n",
      "[ 0.91582734  0.91438849  0.92589928  0.91007194  0.92661871  0.92230216\n",
      "  0.92302158  0.92158273]\n",
      "[ 0.93165468  0.91510791  0.91798561  0.92446043  0.91870504  0.92014388\n",
      "  0.91798561  0.93165468]\n",
      "[ 0.92302158  0.92014388  0.91510791  0.9294964   0.92086331  0.92877698\n",
      "  0.91510791  0.91438849]\n",
      "Iteration 50 on 138\n",
      "[ 0.92158273  0.91870504  0.91438849  0.91654676  0.93309353  0.93093525\n",
      "  0.91654676  0.91582734]\n",
      "[ 0.92733813  0.93093525  0.91438849  0.91726619  0.92374101  0.91942446\n",
      "  0.92517986  0.92446043]\n",
      "[ 0.93453237  0.92589928  0.9323741   0.91870504  0.91942446  0.92446043\n",
      "  0.92805755  0.92589928]\n",
      "[ 0.92517986  0.92086331  0.91726619  0.91798561  0.91294964  0.92158273\n",
      "  0.92661871  0.92805755]\n",
      "[ 0.91798561  0.92374101  0.92446043  0.91798561  0.92230216  0.92158273\n",
      "  0.9294964   0.92374101]\n",
      "[ 0.93021583  0.93093525  0.93381295  0.9352518   0.92589928  0.90647482\n",
      "  0.92158273  0.92805755]\n",
      "[ 0.91582734  0.94100719  0.91582734  0.92158273  0.91438849  0.92805755\n",
      "  0.91726619  0.92661871]\n",
      "[ 0.92230216  0.92446043  0.91654676  0.93021583  0.92086331  0.91654676\n",
      "  0.92733813  0.92446043]\n",
      "[ 0.92589928  0.90935252  0.92446043  0.93309353  0.92086331  0.93309353\n",
      "  0.93165468  0.91942446]\n",
      "[ 0.9294964   0.92302158  0.92014388  0.92877698  0.92589928  0.92733813\n",
      "  0.92230216  0.92589928]\n",
      "Iteration 60 on 138\n",
      "[ 0.92733813  0.91438849  0.92014388  0.92302158  0.91582734  0.92733813\n",
      "  0.92589928  0.91007194]\n",
      "[ 0.92302158  0.93669065  0.91151079  0.93669065  0.91151079  0.91438849\n",
      "  0.92302158  0.92517986]\n",
      "[ 0.92014388  0.91798561  0.92158273  0.92517986  0.93165468  0.92589928\n",
      "  0.92158273  0.92446043]\n",
      "[ 0.92374101  0.91438849  0.91870504  0.9294964   0.92230216  0.91942446\n",
      "  0.91510791  0.91582734]\n",
      "[ 0.93093525  0.92158273  0.91294964  0.93093525  0.92374101  0.92733813\n",
      "  0.93597122  0.93165468]\n",
      "[ 0.92589928  0.91798561  0.91654676  0.9028777   0.91798561  0.92805755\n",
      "  0.92014388  0.92446043]\n",
      "[ 0.91438849  0.92014388  0.91942446  0.92733813  0.92230216  0.92014388\n",
      "  0.91079137  0.92014388]\n",
      "[ 0.93093525  0.92517986  0.92446043  0.92517986  0.91079137  0.93453237\n",
      "  0.92661871  0.91582734]\n",
      "[ 0.92374101  0.92446043  0.92302158  0.91942446  0.91510791  0.91366906\n",
      "  0.92517986  0.92805755]\n",
      "[ 0.93093525  0.92589928  0.92374101  0.91798561  0.92589928  0.92302158\n",
      "  0.9323741   0.91726619]\n",
      "Iteration 70 on 138\n",
      "[ 0.91654676  0.92589928  0.90863309  0.91726619  0.92230216  0.92374101\n",
      "  0.9294964   0.92517986]\n",
      "[ 0.92661871  0.92158273  0.91870504  0.92014388  0.93021583  0.9323741\n",
      "  0.91798561  0.91942446]\n",
      "[ 0.9294964   0.92517986  0.91798561  0.91726619  0.92877698  0.91510791\n",
      "  0.93884892  0.93021583]\n",
      "[ 0.92086331  0.92158273  0.91798561  0.92302158  0.91798561  0.91366906\n",
      "  0.92374101  0.91510791]\n",
      "[ 0.93165468  0.90863309  0.92733813  0.92086331  0.91366906  0.92158273\n",
      "  0.92446043  0.92230216]\n",
      "[ 0.92877698  0.92446043  0.92158273  0.92302158  0.92446043  0.92877698\n",
      "  0.91510791  0.92877698]\n",
      "[ 0.92014388  0.92158273  0.92374101  0.91438849  0.92589928  0.92302158\n",
      "  0.91798561  0.91726619]\n",
      "[ 0.92733813  0.9323741   0.92302158  0.93093525  0.91223022  0.92517986\n",
      "  0.92517986  0.91870504]\n",
      "[ 0.93165468  0.92589928  0.91654676  0.92086331  0.92589928  0.92589928\n",
      "  0.92158273  0.92230216]\n",
      "[ 0.92805755  0.91294964  0.92014388  0.91942446  0.93309353  0.91510791\n",
      "  0.91366906  0.92302158]\n",
      "Iteration 80 on 138\n",
      "[ 0.92661871  0.92086331  0.91223022  0.91582734  0.92302158  0.92877698\n",
      "  0.93021583  0.92230216]\n",
      "[ 0.93381295  0.92158273  0.92158273  0.91582734  0.92302158  0.92086331\n",
      "  0.91798561  0.91870504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.93021583  0.91223022  0.91366906  0.92302158  0.92014388  0.92733813\n",
      "  0.91654676  0.91942446]\n",
      "[ 0.92230216  0.92014388  0.92230216  0.9294964   0.93093525  0.92374101\n",
      "  0.91942446  0.92158273]\n",
      "[ 0.92302158  0.92446043  0.91294964  0.9294964   0.92661871  0.92374101\n",
      "  0.92733813  0.91366906]\n",
      "[ 0.92517986  0.92302158  0.92014388  0.92230216  0.92661871  0.91223022\n",
      "  0.91942446  0.92661871]\n",
      "[ 0.93093525  0.92302158  0.91438849  0.92374101  0.91654676  0.93093525\n",
      "  0.91870504  0.92733813]\n",
      "[ 0.91726619  0.91223022  0.92877698  0.92589928  0.91654676  0.91079137\n",
      "  0.92014388  0.92014388]\n",
      "[ 0.91366906  0.92733813  0.92805755  0.92517986  0.93453237  0.93165468\n",
      "  0.93093525  0.91007194]\n",
      "[ 0.92446043  0.91007194  0.92877698  0.9294964   0.91582734  0.91942446\n",
      "  0.91510791  0.92661871]\n",
      "Iteration 90 on 138\n",
      "[ 0.91294964  0.92014388  0.91582734  0.92302158  0.90143885  0.91438849\n",
      "  0.92733813  0.92302158]\n",
      "[ 0.92517986  0.92014388  0.91942446  0.92446043  0.91510791  0.92733813\n",
      "  0.92877698  0.91942446]\n",
      "[ 0.91726619  0.91654676  0.91942446  0.92302158  0.92661871  0.92302158\n",
      "  0.92805755  0.91798561]\n",
      "[ 0.92805755  0.92230216  0.92230216  0.93165468  0.92086331  0.9294964\n",
      "  0.93093525  0.91726619]\n",
      "[ 0.92302158  0.92446043  0.92302158  0.92446043  0.91870504  0.92302158\n",
      "  0.92230216  0.91007194]\n",
      "[ 0.92517986  0.91942446  0.92014388  0.92733813  0.90719424  0.90935252\n",
      "  0.9057554   0.91151079]\n",
      "[ 0.93021583  0.92733813  0.92446043  0.91438849  0.92374101  0.92014388\n",
      "  0.92446043  0.92877698]\n",
      "[ 0.92158273  0.92589928  0.92733813  0.91510791  0.92733813  0.92014388\n",
      "  0.93021583  0.92446043]\n",
      "[ 0.92661871  0.92302158  0.91726619  0.92805755  0.91870504  0.91942446\n",
      "  0.92517986  0.92086331]\n",
      "[ 0.91942446  0.91654676  0.91870504  0.93669065  0.9352518   0.91726619\n",
      "  0.91223022  0.91079137]\n",
      "Iteration 100 on 138\n",
      "[ 0.92230216  0.92014388  0.92733813  0.91654676  0.92158273  0.92517986\n",
      "  0.92446043  0.92661871]\n",
      "[ 0.92733813  0.91798561  0.92517986  0.92589928  0.91942446  0.92302158\n",
      "  0.92661871  0.91151079]\n",
      "[ 0.92805755  0.91798561  0.91654676  0.91654676  0.91582734  0.93093525\n",
      "  0.92446043  0.9028777 ]\n",
      "[ 0.92805755  0.91870504  0.91942446  0.92805755  0.91942446  0.92805755\n",
      "  0.92374101  0.91798561]\n",
      "[ 0.92517986  0.91151079  0.91870504  0.92517986  0.91582734  0.91510791\n",
      "  0.91007194  0.92374101]\n",
      "[ 0.93669065  0.92661871  0.90935252  0.92517986  0.92302158  0.92517986\n",
      "  0.92014388  0.93381295]\n",
      "[ 0.92446043  0.91366906  0.91654676  0.92446043  0.92446043  0.91654676\n",
      "  0.91726619  0.92446043]\n",
      "[ 0.91582734  0.94100719  0.91438849  0.91510791  0.92014388  0.92158273\n",
      "  0.91079137  0.91726619]\n",
      "[ 0.92517986  0.92589928  0.91654676  0.92877698  0.91654676  0.92230216\n",
      "  0.91438849  0.92517986]\n",
      "[ 0.93453237  0.92302158  0.91726619  0.92230216  0.92014388  0.9323741\n",
      "  0.92877698  0.91870504]\n",
      "Iteration 110 on 138\n",
      "[ 0.92661871  0.91798561  0.92086331  0.9294964   0.91582734  0.91798561\n",
      "  0.92302158  0.91942446]\n",
      "[ 0.94532374  0.92877698  0.91007194  0.9294964   0.92589928  0.92446043\n",
      "  0.92302158  0.91223022]\n",
      "[ 0.9323741   0.91223022  0.92374101  0.91438849  0.92158273  0.92014388\n",
      "  0.92014388  0.93884892]\n",
      "[ 0.91582734  0.92014388  0.92805755  0.93021583  0.92374101  0.91366906\n",
      "  0.91079137  0.91798561]\n",
      "[ 0.92014388  0.92302158  0.92158273  0.91079137  0.91438849  0.91942446\n",
      "  0.92158273  0.93597122]\n",
      "[ 0.93165468  0.93165468  0.91366906  0.92446043  0.93597122  0.92877698\n",
      "  0.92517986  0.91294964]\n",
      "[ 0.91510791  0.93453237  0.91798561  0.92086331  0.91366906  0.92733813\n",
      "  0.92446043  0.92158273]\n",
      "[ 0.92517986  0.91438849  0.92230216  0.91870504  0.92302158  0.92661871\n",
      "  0.91870504  0.92014388]\n",
      "[ 0.92517986  0.91151079  0.92805755  0.91438849  0.92877698  0.92014388\n",
      "  0.92086331  0.91438849]\n",
      "[ 0.91294964  0.92086331  0.91942446  0.89856115  0.92302158  0.91151079\n",
      "  0.90647482  0.91366906]\n",
      "Iteration 120 on 138\n",
      "[ 0.90503597  0.92805755  0.91366906  0.91079137  0.91582734  0.91294964\n",
      "  0.92014388  0.91870504]\n",
      "[ 0.90431655  0.91294964  0.91582734  0.90719424  0.9         0.91942446\n",
      "  0.91582734  0.91942446]\n",
      "[ 0.89856115  0.91438849  0.91366906  0.91079137  0.90359712  0.91007194\n",
      "  0.9057554   0.91654676]\n",
      "[ 0.92661871  0.89928058  0.92374101  0.9057554   0.90863309  0.90935252\n",
      "  0.90935252  0.92230216]\n",
      "[ 0.90431655  0.92014388  0.90503597  0.9057554   0.90071942  0.8971223\n",
      "  0.9057554   0.90431655]\n",
      "[ 0.9         0.9028777   0.88992806  0.8942446   0.89856115  0.88848921\n",
      "  0.90359712  0.8971223 ]\n",
      "[ 0.84316547  0.86330935  0.8705036   0.87122302  0.86546763  0.85251799\n",
      "  0.86043165  0.85755396]\n",
      "[ 0.85323741  0.85827338  0.85251799  0.86546763  0.85323741  0.85251799\n",
      "  0.84388489  0.8618705 ]\n",
      "[ 0.84820144  0.86115108  0.83453237  0.86115108  0.84532374  0.85683453\n",
      "  0.84892086  0.83669065]\n",
      "[ 0.84028777  0.84820144  0.83597122  0.84532374  0.85251799  0.84244604\n",
      "  0.83309353  0.84172662]\n",
      "Iteration 130 on 138\n",
      "[ 0.78561151  0.76618705  0.78920863  0.79640288  0.78345324  0.76690647\n",
      "  0.78848921  0.78561151]\n",
      "[ 0.7647482   0.75899281  0.76546763  0.7647482   0.76258993  0.75827338\n",
      "  0.75683453  0.75107914]\n",
      "[ 0.75107914  0.75683453  0.74892086  0.7381295   0.73165468  0.74604317\n",
      "  0.75395683  0.72446043]\n",
      "[ 0.73381295  0.72086331  0.73309353  0.74316547  0.73021583  0.74028777\n",
      "  0.75395683  0.71582734]\n",
      "[ 0.71294964  0.68273381  0.71366906  0.7057554   0.71294964  0.71366906\n",
      "  0.72158273  0.71007194]\n",
      "[ 0.6971223   0.68992806  0.68920863  0.68129496  0.68345324  0.69568345\n",
      "  0.68705036  0.7057554 ]\n",
      "[ 0.51798561  0.51366906  0.54028777  0.50647482  0.53669065  0.51151079\n",
      "  0.53453237  0.50431655]\n",
      "[ 0.46402878  0.4294964   0.51294964  0.47553957  0.44100719  0.44964029\n",
      "  0.47266187  0.45539568]\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for thresh in thresholds:\n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "    select_X_train = selection.transform(X_train_plus_i)\n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "    # train model\n",
    "    selection_model = XGBClassifier(nthread=4, **params1)\n",
    "    scores = cross_val_pimped(selection_model, select_X_train, y_train, 8)\n",
    "\n",
    "    results[i,0] = np.mean(scores)\n",
    "    results[i,1] = np.std(scores)\n",
    "    results[i,2] = thresh\n",
    "    i=i+1\n",
    "    if i % 10 == 0:\n",
    "        print('Iteration',i,'on', len(thresholds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       [  9.26169065e-01,   5.19952177e-03,   0.00000000e+00],\n",
    "       \n",
    "       [  9.25449640e-01,   5.74343969e-03,   0.00000000e+00],\n",
    "       \n",
    "       [  9.25089928e-01,   2.37076013e-03,   0.00000000e+00],\n",
    "       \n",
    "       [  9.26888489e-01,   6.80548066e-03,   2.26323120e-03],\n",
    "       \n",
    "       [  9.25359712e-01,   7.57747282e-03,   4.70055733e-03],\n",
    "       \n",
    "       [  9.25179856e-01,   8.18691128e-03,   7.13788299e-03],\n",
    "       \n",
    "       [  9.25359712e-01,   4.99404438e-03,   8.70473497e-03],\n",
    "       \n",
    "       [  9.25000000e-01,   7.82115644e-03,   1.27089135e-02],\n",
    "       \n",
    "       [  9.25539568e-01,   7.86446443e-03,   1.65389981e-02],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold : 0.0022632312\n"
     ]
    }
   ],
   "source": [
    "best_tresh = 2.26323120e-03\n",
    "print('Best threshold :' ,best_tresh)\n",
    "selection = SelectFromModel(model, threshold=best_tresh, prefit=False)\n",
    "selection.fit(X_train_plus_i, y_train)\n",
    "select_X_train_plus = selection.transform(X_train_plus_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imputer = Imputer(strategy = 'median')\n",
    "X_test_i = imputer.fit_transform(X_test)\n",
    "feature_1 = X_test_i[:,21]*X_test_i[:,24] + X_test_i[:,26]\n",
    "feature_2 = X_test_i[:,46]/(X_test_i[:,26]+0.0001)\n",
    "feature_3 = X_test_i[:,17]-X_test_i[:,33]\n",
    "feature_4 = X_test_i[:,10]*X_test_i[:,43]\n",
    "feature_5 = X_test_i[:,12]-X_test_i[:,45]\n",
    "feature_6 = X_test_i[:,20]+X_test_i[:,61]\n",
    "feature_7 = X_test_i[:,1]-X_test_i[:,44]\n",
    "feature_8 = X_test_i[:,26]+X_test_i[:,31]/(X_test_i[:,14]+0.0001)\n",
    "feature_9 = X_test_i[:,23]/(X_test_i[:,26]+0.0001)\n",
    "features = np.c_[feature_1,\n",
    "                 feature_2,\n",
    "                 feature_3,\n",
    "                 feature_4,\n",
    "                 feature_5,\n",
    "                 feature_6,\n",
    "                 feature_7,\n",
    "                 feature_8,\n",
    "                 feature_9]\n",
    "feature_nan = np.sum(np.isnan(X_test),axis=1)\n",
    "X_test_plus = np.c_[X_test, np.isnan(X_test), features, feature_nan]\n",
    "imputer = Imputer(strategy = 'median')\n",
    "X_test_plus_i = imputer.fit_transform(X_test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select_X_test_plus = selection.transform(X_test_plus_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4987, 74)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_X_test_plus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"select_X_test_plus\", select_X_test_plus, delimiter=\";\")\n",
    "np.savetxt(\"select_X_train_plus\", select_X_train_plus, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
