---
---

@inproceedings{yousfi20imagenet,
  abbr={WIFS},
  author={Y. Yousfi, J. Butora, E. Khvedchenya and J. Fridrich},
  booktitle={IEEE International Workshop on Information Forensics and Security}, 
  title={ImageNet Pre-trained CNNs for JPEG Steganalysis}, 
  year={2020},
  abstract={In this paper, we investigate pre-trained computervision deep architectures, such as the EfficientNet, MixNet, and ResNet for steganalysis. These models pre-trained on ImageNet can be rather quickly refined for JPEG steganalysis while offering significantly better performance than CNNs designed purposely for steganalysis, such as the SRNet, trained from scratch. We show how different architectures compare on the ALASKA II dataset. We demonstrate that avoiding pooling/stride in the first layers enables better performance, as noticed by other top competitors, which aligns with the design choices of many CNNs designed for steganalysis. We also show how pre-trained computer-vision deep architectures perform on the ALASKA I dataset.},
  pdf={http://www.ws.binghamton.edu/fridrich/Research/Alaska-2-Revised.pdf},
  selected={true}
}


@article{yousfi20onehot,
  abbr={SPL},
  author={Y. Yousfi and J. Fridrich},
  journal={IEEE Signal Processing Letters}, 
  title={An Intriguing Struggle of {CNNs} in {JPEG} Steganalysis and the OneHot Solution}, 
  year={2020},
  volume={27},
  pages={830-834},
  abstract={Deep convolutional neural networks (CNNs) have become the tool of choice for steganalysis because they outperform older feature-based detectors by a large margin. However, recent work points at cases where feature-based detectors perform better than CNNs due to their failure to compute simple statistics of DCT coefficients. We introduce a shallow “OneHot” CNN, which encodes DCT coefficients using clipped one-hot encoding into a binary volumetric representation of the DCT plane fed to a convolutional block designed to learn relevant intra-block and inter-block relationships using vanilla and dilated convolutions. Methodology for plugging the “OneHot” network into conventional steganalysis CNNs is also introduced for an end-to-end learnable detector with improved performance},
  pdf={http://www.ws.binghamton.edu/fridrich/Research/OneHot_Revised.pdf},
  selected={true}
}


@inproceedings{yousfi20ei,
  abbr={EI},
  author = {Y. Yousfi and J. Fridrich},
  title = {{JPEG} steganalysis detectors scalable with respect to compression quality},
  booktitle ={Proceedings {IS\&T}, Electronic Imaging, Media Watermarking, Security, and Forensics},
  year = {2020},
  month = {January 26--30,},
  address = {San Francisco, CA},
  editor = {A. Alattar and N. D. Memon},
  abstract = {Practical steganalysis inevitably involves the necessity to deal with a diverse cover source. In the JPEG domain, one key element of the diversification is the JPEG quality factor, or, more generally, the JPEG quantization table used for compression. This paper investigates experimentally the scalability of various steganalysis detectors w.r.t. JPEG quality. In particular, we report that CNN detectors as well as older feature-based detectors have the capacity to contain the complexity of multiple JPEG quality factors within a single model when the quality factors are properly grouped based on their quantization tables. Detectors trained on multiple JPEG qualities show no loss of detection accuracy when compared with dedicated detectors trained for a specific JPEG quality factor. We also demonstrate that CNNs (but not so much feature-based classifiers) trained on multiple qualities can generalize to unseen custom quantization tables compared to detectors trained for specific JPEG qualities. Their ability to generalize to very different quantization tables, however, remains a challenging task. A semi-metric comparing quantization tables is introduced and used to interpret our results.},
  pdf={http://www.ws.binghamton.edu/fridrich/Research/scalable_jpeg_steganalysis.pdf},
  selected={true}
}


@Inproceedings{but20ih,
  abbr={IH},
  author = {J. Butora, Y. Yousfi and J. Fridrich},
  title = {Turning Cost-Based Steganography into Model-Based},
  booktitle = {The 8th ACM Workshop on Information Hiding and Multimedia Security},
  year = {2020},
  editor = {R. Cogranne and L. Verdoliva},
  address = {Denver, CO, USA},
  month = {July 3--5,},
  publisher = {{ACM} Press},
  abstract = {Most modern steganographic schemes embed secrets by minimizing the total expected cost of modifications. However, costs are usually computed using heuristics and cannot be directly linked to statistical detectability. Moreover, as previously shown by Ker at al., cost-based schemes fundamentally minimize the wrong quantity that makes them more vulnerable to knowledgeable adversary aware of the embedding change rates. In this paper, we research the possibility to convert cost-based schemes to model-based ones by postulating that there exists payload size for which the change rates derived from costs coincide with change rates derived from some (not necessarily known) model. This allows us to find the steganographic Fisher information for each pixel (DCT coefficient), and embed other payload sizes by minimizing deflection. This rather simple measure indeed brings sometimes quite significant improvements in security especially with respect to steganalysis aware of the selection channel. Steganographic algorithms in both spatial and JPEG domains are studied with feature-based classifiers as well as CNNs.},
  pdf={http://www.ws.binghamton.edu/fridrich/Research/cost2model-10.pdf},
  selected={false}
}


@inproceedings{yousfi20successife,
  author={Y. Yousfi, E. Akyol},
  booktitle={ASILOMAR Conference on Signals, Systems and Computers}, 
  title={(Under preparation) Successive Information Bottleneck and applications in Deep Learning}, 
  year={2020},
}


@Inproceedings{You19ih,
  abbr={IH},
  author = {Y. Yousfi and J. Butora and Q. Giboulot and J. Fridrich},
  title = {Breaking {ALASKA}: Color Separation for Steganalysis in {JPEG} Domain},
  booktitle = {The 7th ACM Workshop on Information Hiding and Multimedia Security},
  year = {2019},
  editor = {R. Cogranne and L. Verdoliva},
  address = {Paris, France},
  month = {July 3--5,},
  publisher = {{ACM} Press},
  abstract = {This paper describes the architecture and training of detectors developed for the ALASKA steganalysis challenge. For each quality factor in the range 60–98, several multi-class tile detectors implemented as SRNets were trained on various combinations of three input channels: luminance and two chrominance channels. To accept images of arbitrary size, the detector for each quality factor was a multi-class multi-layered perceptron trained on features extracted by the tile detectors. For quality 99 and 100, a new “reverse JPEG compatibility attack” was developed and also implemented using the SRNet via the tile detector. Throughout the paper, we explain various improvements we discovered during the course of the competition and discuss the challenges we encountered and trade offs that had to be adopted in order to build a detector capable of detecting steganographic content in a stego source of great diversity.},
  pdf={http://www.ws.binghamton.edu/fridrich/Research/ALASKA-preprint1.pdf},
  selected={true}
}

