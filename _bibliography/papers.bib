---
---

@inproceedings{pretrain21ih,
  abbr={IH},
  author = {J. Butora and Y. Yousfi and J. Fridrich},
  title = {How to Pretrain for Stegnalysis},
  booktitle = {The 9th ACM Workshop on Information Hiding and Multimedia Security},
  year = {2021},
  address = {Brussels, Belgium},
  month = {June 22--25,},
  publisher = {{ACM} Press},
  abstract = {In this paper, we investigate the effect of pretraining CNNs on ImageNet on their performance when refined for steganalysis of digital images. In many cases, it seems that just ’seeing’ a large number of images helps with the convergence of the network during the refinement no matter what the pretraining task is. To achieve the best performance, the pretraining task should be related to steganalysis, even if it is done on a completely mismatched cover and stego datasets. Furthermore, the pretraining does not need to be carried out for very long and can be done with limited computational resources. An additional advantage of the pretraining is that it is done on color images and can later be applied for steganalysis of color and grayscale images while still having on-par or better performance than detectors trained specifically for a given source. The refining process is also much faster than training the network from scratch. The most surprising part of the paper is that networks pretrained on JPEG images are a good starting point for spatial domain steganalysis as well.},
  pdf={http://www.ws.binghamton.edu/fridrich/Research/IN-pretraining-6.pdf},
  selected={false}
}

@inproceedings{surgeries21ih,
  abbr={IH},
  author = {Y. Yousfi and J. Butora and J. Fridrich and C. Fuji-Tsang},
  title = {Improving EfficientNet for JPEG Steganalysis},
  booktitle = {The 9th ACM Workshop on Information Hiding and Multimedia Security},
  year = {2021},
  address = {Brussels, Belgium},
  month = {June 22--25,},
  publisher = {{ACM} Press},
  abstract = {In this paper, we study the EfficientNet family pre-trained on ImageNet when used for steganalysis using transfer learning. We show that certain “surgical modifications” aimed at maintaining the input resolution in EfficientNet architectures significantly boost their performance in JPEG steganalysis, establishing thus new benchmarks. The modified models are evaluated by their detection accuracy, the number of parameters, the memory consumption, and the total floating point operations (FLOPs) on the ALASKA II dataset. We also show that, surprisingly, EfficientNets in their “vanilla form” do not perform as well as the SRNet in BOSSbase+BOWS2. This is because, unlike ALASKA II images, BOSSbase+BOWS2 contains aggressively subsampled images with more complex content. The surgical modifications in EfficientNet remedy this underperformance as well.},
  selected={true},
  pdf={http://www.ws.binghamton.edu/fridrich/Research/11_SURGERIES_v8_preprint.pdf}
}

@inproceedings{yousfi20imagenet,
  abbr={WIFS},
  author={Y. Yousfi and J. Butora and E. Khvedchenya and J. Fridrich},
  booktitle={IEEE International Workshop on Information Forensics and Security}, 
  title={ImageNet Pre-trained CNNs for JPEG Steganalysis}, 
  year={2020},
  abstract={In this paper, we investigate pre-trained computervision deep architectures, such as the EfficientNet, MixNet, and ResNet for steganalysis. These models pre-trained on ImageNet can be rather quickly refined for JPEG steganalysis while offering significantly better performance than CNNs designed purposely for steganalysis, such as the SRNet, trained from scratch. We show how different architectures compare on the ALASKA II dataset. We demonstrate that avoiding pooling/stride in the first layers enables better performance, as noticed by other top competitors, which aligns with the design choices of many CNNs designed for steganalysis. We also show how pre-trained computer-vision deep architectures perform on the ALASKA I dataset.},
  pdf={http://www.ws.binghamton.edu/fridrich/Research/Alaska-2-Revised.pdf}, 
  video={https://drive.google.com/file/d/1CTfo0_12pCnrM-vaMUcn7ifUJOMZiqg5/view?usp=sharing},
  code={https://github.com/BloodAxe/Kaggle-2020-Alaska2},
  selected={true}
}


@article{yousfi20onehot,
  abbr={SPL},
  author={Y. Yousfi and J. Fridrich},
  journal={IEEE Signal Processing Letters}, 
  title={An Intriguing Struggle of {CNNs} in {JPEG} Steganalysis and the OneHot Solution}, 
  year={2020},
  volume={27},
  pages={830-834},
  abstract={Deep convolutional neural networks (CNNs) have become the tool of choice for steganalysis because they outperform older feature-based detectors by a large margin. However, recent work points at cases where feature-based detectors perform better than CNNs due to their failure to compute simple statistics of DCT coefficients. We introduce a shallow “OneHot” CNN, which encodes DCT coefficients using clipped one-hot encoding into a binary volumetric representation of the DCT plane fed to a convolutional block designed to learn relevant intra-block and inter-block relationships using vanilla and dilated convolutions. Methodology for plugging the “OneHot” network into conventional steganalysis CNNs is also introduced for an end-to-end learnable detector with improved performance},
  pdf={http://www.ws.binghamton.edu/fridrich/Research/OneHot_Revised.pdf},
  code={https://github.com/YassineYousfi/OneHotConv},
  selected={true}
}


@inproceedings{yousfi20ei,
  abbr={EI},
  author = {Y. Yousfi and J. Fridrich},
  title = {{JPEG} steganalysis detectors scalable with respect to compression quality},
  booktitle ={Proceedings {IS\&T}, Electronic Imaging, Media Watermarking, Security, and Forensics},
  year = {2020},
  month = {January 26--30,},
  address = {San Francisco, CA},
  editor = {A. Alattar and N. D. Memon},
  abstract = {Practical steganalysis inevitably involves the necessity to deal with a diverse cover source. In the JPEG domain, one key element of the diversification is the JPEG quality factor, or, more generally, the JPEG quantization table used for compression. This paper investigates experimentally the scalability of various steganalysis detectors w.r.t. JPEG quality. In particular, we report that CNN detectors as well as older feature-based detectors have the capacity to contain the complexity of multiple JPEG quality factors within a single model when the quality factors are properly grouped based on their quantization tables. Detectors trained on multiple JPEG qualities show no loss of detection accuracy when compared with dedicated detectors trained for a specific JPEG quality factor. We also demonstrate that CNNs (but not so much feature-based classifiers) trained on multiple qualities can generalize to unseen custom quantization tables compared to detectors trained for specific JPEG qualities. Their ability to generalize to very different quantization tables, however, remains a challenging task. A semi-metric comparing quantization tables is introduced and used to interpret our results.},
  pdf={http://www.ws.binghamton.edu/fridrich/Research/scalable_jpeg_steganalysis.pdf},
  selected={true}
}


@Inproceedings{but20ih,
  abbr={IH},
  author = {J. Butora and Y. Yousfi and J. Fridrich},
  title = {Turning Cost-Based Steganography into Model-Based},
  booktitle = {The 8th ACM Workshop on Information Hiding and Multimedia Security},
  year = {2020},
  editor = {R. Cogranne and L. Verdoliva},
  address = {Denver, CO, USA},
  month = {July 3--5,},
  publisher = {{ACM} Press},
  abstract = {Most modern steganographic schemes embed secrets by minimizing the total expected cost of modifications. However, costs are usually computed using heuristics and cannot be directly linked to statistical detectability. Moreover, as previously shown by Ker at al., cost-based schemes fundamentally minimize the wrong quantity that makes them more vulnerable to knowledgeable adversary aware of the embedding change rates. In this paper, we research the possibility to convert cost-based schemes to model-based ones by postulating that there exists payload size for which the change rates derived from costs coincide with change rates derived from some (not necessarily known) model. This allows us to find the steganographic Fisher information for each pixel (DCT coefficient), and embed other payload sizes by minimizing deflection. This rather simple measure indeed brings sometimes quite significant improvements in security especially with respect to steganalysis aware of the selection channel. Steganographic algorithms in both spatial and JPEG domains are studied with feature-based classifiers as well as CNNs.},
  pdf={http://www.ws.binghamton.edu/fridrich/Research/cost2model-10.pdf},
  selected={false}
}


@inproceedings{yousfi20successife,
  author={Y. Yousfi and E. Akyol},
  booktitle={ASILOMAR Conference on Signals, Systems and Computers}, 
  title={(Under preparation) Successive Information Bottleneck and applications in Deep Learning}, 
  year={2020},
  abstract ={Information Bottleneck (IB) method studies the trade-off between compression and prediction:  extracting relevant information from the input variable $X$ while preserving relevant information about another random variable $Y$, the resulting representation is another random variable $Z$.  Motivated by the deep neural networks implementations,  this paper studies a novel variation of the $N$-layer IB problem where the layers are assumed to be encoded in a successive fashion. We propose a method for performing an N-Layer IB in a greedy fashion and analyze numerical results obtained over a set of  synthetic experiments.}
}


@Inproceedings{You19ih,
  abbr={IH},
  author = {Y. Yousfi and J. Butora and Q. Giboulot and J. Fridrich},
  title = {Breaking {ALASKA}: Color Separation for Steganalysis in {JPEG} Domain},
  booktitle = {The 7th ACM Workshop on Information Hiding and Multimedia Security},
  year = {2019},
  editor = {R. Cogranne and L. Verdoliva},
  address = {Paris, France},
  month = {July 3--5,},
  publisher = {{ACM} Press},
  abstract = {This paper describes the architecture and training of detectors developed for the ALASKA steganalysis challenge. For each quality factor in the range 60–98, several multi-class tile detectors implemented as SRNets were trained on various combinations of three input channels: luminance and two chrominance channels. To accept images of arbitrary size, the detector for each quality factor was a multi-class multi-layered perceptron trained on features extracted by the tile detectors. For quality 99 and 100, a new “reverse JPEG compatibility attack” was developed and also implemented using the SRNet via the tile detector. Throughout the paper, we explain various improvements we discovered during the course of the competition and discuss the challenges we encountered and trade offs that had to be adopted in order to build a detector capable of detecting steganographic content in a stego source of great diversity.},
  pdf={http://www.ws.binghamton.edu/fridrich/Research/ALASKA-preprint1.pdf},
  selected={true}
}

